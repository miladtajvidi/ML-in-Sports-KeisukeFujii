# References

[1- When will you do what? - Anticipating Temporal Occurrences of Activities(2018)](https://arxiv.org/abs/1804.00892) <br>
[2- Reidentifying soccer players in broadcast videos using body feature alignment based on pose(2023) ](https://dl.acm.org/doi/abs/10.1145/3603781.3603860) <br>
[3- An enhanced swin transformer for soccer player reidentification(2024)](https://www.researchgate.net/publication/377334439_An_enhanced_Swin_Transformer_for_soccer_player_reidentification) <br>
[4- An efficient algorithm for detection of soccer ball and players(2012)](https://www.researchgate.net/publication/276270309_An_Efficient_Algorithm_for_Detection_of_Soccer_Ball_and_Players) <br>
[5- Attention-aware multiple granularities network for player re-identification(2022)](https://www.researchgate.net/publication/364303154_Attention-Aware_Multiple_Granularities_Network_for_Player_Re-Identification) <br>
[6- 2D human pose estimation: new benchmark and state of the art analysis(2014)](https://openaccess.thecvf.com/content_cvpr_2014/papers/Andriluka_2D_Human_Pose_2014_CVPR_paper.pdf) <br>
[7- Single-camera basketball tracker through pose
and semantic feature fusion (2019)](https://arxiv.org/abs/1906.02042) <br>
[8- Using playerâ€™s bodyorientation to model pass feasibility in soccer(2020)](https://arxiv.org/abs/2004.07209) <br>
[9-  Interaction classification with key actor detection in multi-person sports videos(2022)](https://openaccess.thecvf.com/content/CVPR2022W/CVSports/papers/Askari_Interaction_Classification_With_Key_Actor_Detection_in_Multi-Person_Sports_Videos_CVPRW_2022_paper.pdf) <br>
[10- Video interaction recognition using an attention augmented relational network and skeleton data(2024)](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/papers/Askari_Video_Interaction_Recognition_using_an_Attention_Augmented_Relational_Network_and_CVPRW_2024_paper.pdf) <br>
[11- Soccer players identification based on
visual local features(2007)](https://www.researchgate.net/publication/210113142_Soccer_Players_Identification_Based_on_Visual_Local_Features) <br>
[12- My view is the best view: procedure learning from egocentric videos(2022)](https://arxiv.org/abs/2207.10883) <br>
[13- Monocular 3D human pose estimation for sports broadcasts using partial sports field registration(2023)](https://arxiv.org/abs/2304.04437) <br>
[14- Unified fully and timestamp supervised temporal action segmentation via sequence to sequence translation(2022)](https://arxiv.org/abs/2209.00638) <br>
[15- Racing bib numbers recognition(2012)](https://people.csail.mit.edu/talidekel/papers/RBNR.pdf) <br>
[16- OSL-ActionSpotting: A Unified Library for Action Spotting in Sports Videos(2024)](https://arxiv.org/abs/2407.01265) <br>
[17- Tracking without bells and whistles(2019)](https://arxiv.org/abs/1903.05625) <br>
[18- Simple online and realtime tracking(2016)](https://www.researchgate.net/publication/307516256_Simple_online_and_realtime_tracking) <br>
[19- A Unified Taxonomy and Multimodal Dataset for Events in Invasion Games(2021)](https://arxiv.org/abs/2108.11149) <br>
[20- Learning a Neural Solver for Multiple Object Tracking(2020)](https://openaccess.thecvf.com/content_CVPR_2020/html/Braso_Learning_a_Neural_Solver_for_Multiple_Object_Tracking_CVPR_2020_paper.html) <br>
[21- Multi-Person 3D Pose Estimation and Tracking in Sports(2019)](https://openaccess.thecvf.com/content_CVPRW_2019/html/CVSports/Bridgeman_Multi-Person_3D_Pose_Estimation_and_Tracking_in_Sports_CVPRW_2019_paper.html) <br>
[22- PitcherNet: Powering the Moneyball Evolution in Baseball Video Analytics(2024)](https://arxiv.org/abs/2405.07407) <br>
[23- Beyond the Premier: Assessing Action Spotting Transfer Capability Across Diverse Domains(2024)](https://openaccess.thecvf.com/content/CVPR2024W/CVsports/html/Cabado_Beyond_the_Premier_Assessing_Action_Spotting_Transfer_Capability_Across_Diverse_CVPRW_2024_paper.html) <br>
[24- Observation-centric sort: Rethinking sort for robust multi-object tracking(2023)](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Observation-Centric_SORT_Rethinking_SORT_for_Robust_Multi-Object_Tracking_CVPR_2023_paper.pdf) <br>
[25- OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields(2019)](https://arxiv.org/abs/1812.08008) <br>
[26- End-to-End Object Detection with Transformers(2020)](https://arxiv.org/abs/2005.12872) <br>
[27- Pointless calibration: Camera parameters from gradient-based alignment to edge images(2012)](https://www.researchgate.net/publication/254056672_Pointless_calibration_Camera_parameters_from_gradient-based_alignment_to_edge_images) <br>
[28- 3D Ball Trajectory Reconstruction of a Ballistic Shot from a Monocular Basketball Video(2023)](https://www.researchgate.net/publication/375702396_3D_Ball_Trajectory_Reconstruction_of_a_Ballistic_Shot_from_a_Monocular_Basketball_Video) <br>
[29- Sports Camera Calibration via Synthetic Data(2019)](https://openaccess.thecvf.com/content_CVPRW_2019/papers/CVSports/Chen_Sports_Camera_Calibration_via_Synthetic_Data_CVPRW_2019_paper.pdf) <br>
[30- Dynamic model based ball trajectory prediction for a robot ping-pong player(2010)](https://www.researchgate.net/publication/251992166_Dynamic_model_based_ball_trajectory_prediction_for_a_robot_ping-pong_player) <br>
[31- HigherHRNet: Scale-Aware Representation Learning for Bottom-Up Human Pose Estimation(2020)](https://openaccess.thecvf.com/content_CVPR_2020/papers/Cheng_HigherHRNet_Scale-Aware_Representation_Learning_for_Bottom-Up_Human_Pose_Estimation_CVPR_2020_paper.pdf) <br>
[32- Player tracking and analysis of basketball plays(2015)](https://web.stanford.edu/class/ee368/Project_Spring_1415/Posters/Cheshire_Halasz_Perin.pdf) <br>
[33- Sports Field Registration via Keypoints-Aware Label Condition(2022)](https://openaccess.thecvf.com/content/CVPR2022W/CVSports/html/Chu_Sports_Field_Registration_via_Keypoints-Aware_Label_Condition_CVPRW_2022_paper.html) <br>
[34- A Context-Aware Loss Function for Action Spotting in Soccer Videos(2020)](https://arxiv.org/abs/1912.01326) <br>
[35- Scaling up SoccerNet with multi-view spatial localization and re-identification(2022)](https://www.researchgate.net/publication/361442319_Scaling_up_SoccerNet_with_multi-view_spatial_localization_and_re-identification) <br>
[36- SoccerNet-Tracking: Multiple Object Tracking Dataset and Benchmark in Soccer Videos(2022)](https://arxiv.org/abs/2204.06918) <br>
[37- SoccerNet 2023 Challenges Results(2024)](https://arxiv.org/abs/2309.06006) <br>
[38- Real-Time Camera Pose Estimation for Sports Fields(2020)](https://arxiv.org/abs/2003.14109) <br>
[39-]() <br>
[40-]() <br>
[41-]() <br>
[42-]() <br>
[43-]() <br>
[44-]() <br>
[45-]() <br>
[46-]() <br>
[47-]() <br>
[48-]() <br>
[49-]() <br>
[50-]() <br>
[51-]() <br>
[52-]() <br>
[53-]() <br>
[54-]() <br>
[55-]() <br>
[56-]() <br>
[57-]() <br>
[58-]() <br>
[59-]() <br>
[60-]() <br>
[61-]() <br>
[62-]() <br>
[63-]() <br>
[64-]() <br>
[65-]() <br>
[66-]() <br>
[67-]() <br>
[68-]() <br>
[69-]() <br>
[70-]() <br>
[71-]() <br>
[72-]() <br>
[73-]() <br>
[74-]() <br>
[75-]() <br>
[76-]() <br>
[77-]() <br>
[78-]() <br>
[79-]() <br>
[80-]() <br>
[81-]() <br>
[82-]() <br>
[83-]() <br>
[84-]() <br>
[85-]() <br>
[86-]() <br>
[87-]() <br>
[88-]() <br>
[89-]() <br>
[90-]() <br>
[91-]() <br>
[92-]() <br>
[93-]() <br>
[94-]() <br>
[95-]() <br>
[96-]() <br>
[97-]() <br>
[98-]() <br>
[99-]() <br>
[100-]() <br>
[101-]() <br>
[102-]() <br>
[103-]() <br>
[104-]() <br>
[105-]() <br>
[106-]() <br>
[107-]() <br>
[108-]() <br>
[109-]() <br>
[110-]() <br>
[111-]() <br>
[112-]() <br>
[113-]() <br>
[114-]() <br>
[115-]() <br>
[116-]() <br>
[117-]() <br>
[118-]() <br>
[119-]() <br>
[120-]() <br>
[121-]() <br>
[122-]() <br>
[123-]() <br>
[124-]() <br>
[125-]() <br>
[126-]() <br>
[127-]() <br>
[128-]() <br>
[129-]() <br>
[130-]() <br>
[131-]() <br>
[132-]() <br>
[133-]() <br>
[134-]() <br>
[135-]() <br>
[136-]() <br>
[137-]() <br>
[138-]() <br>
[139-]() <br>
[140-]() <br>
[141-]() <br>
[142-]() <br>
[143-]() <br>
[144-]() <br>
[145-]() <br>
[146-]() <br>
[147-]() <br>
[148-]() <br>
[149-]() <br>
[150-]() <br>
[151-]() <br>
[152-]() <br>
[153-]() <br>
[154-]() <br>
[155-]() <br>
[156-]() <br>
[157-]() <br>
[158-]() <br>
[159-]() <br>
[160-]() <br>
[161-]() <br>
[162-]() <br>
[163-]() <br>
[164-]() <br>
[165-]() <br>
[166-]() <br>
[167-]() <br>
[168-]() <br>
[169-]() <br>
[170-]() <br>
[171-]() <br>
[172-]() <br>
[173-]() <br>
[174-]() <br>
[175-]() <br>
[176-]() <br>
[177-]() <br>
[178-]() <br>
[179-]() <br>
[180-]() <br>
[181-]() <br>
[182-]() <br>
[183-]() <br>
[184-]() <br>
[185-]() <br>
[186-]() <br>
[187-]() <br>
[188-]() <br>
[189-]() <br>
[190-]() <br>
[191-]() <br>
[192-]() <br>
[193-]() <br>
[194-]() <br>
[195-]() <br>


